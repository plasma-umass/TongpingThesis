\label{sec:relatedwork}
\subsection{Code Profiling and Data Profiling}
There are many studies which helps to improve performance of application. Some of them are using profiling technique, such as
Gprof~\cite{gprof}, Oprofile~\cite{oprofile} and HPCToolkit~\cite{HPCToolKit}. Code profiles are trying to gather 
runtime information about the programs, then attribute execution behavior (like execution time, call times and cache miss) to 
different function or code. Hopefully programmers can use those execution information to find the bottleneck of program. 
But unfornately, those profiling tools didn't provide enough information for user to figure out actual program.
For example, Oprofile can provide L2 cache misses information for each function. Cache misses can have several different causes,
compulsory misses, conflict misses or capacity misses. They can also caused by false sharing or true sharing~\cite{DProf}. 
That means that programmer stills needs lots of effort to locate the actual problem. Also,
they are far from to work as a false sharing detection tool, it is better to use them as a tool to give a overview about one application.
DProf~\cite{DProf} are trying to help programmers to understand cache misses .
\begin{comment}
Profiling tools: 
DProf are based on performance monitoring hardware to 
help programmers to locate cache performanmce problems caused by different data types. 
DProf tries to associate memory addresses with data types and use data flow to find the cache problems related to 
the same type of objects. It is not intend to find false sharing problems of general multithreaded applications. 
\begin{itemize}
\item
First, it can not work on randomly data type. The difference of DProf with PTU is that DProf tries 
to attribute cache misses to different data types.
For the problem like Fig.~\ref{fig:reverseindex}, the data types 
are just multiple of integers. It is impossible to profile for this type of data types since there 
are huge amounts of integers in one application.

\item
DProf are trying to provide a ``data flow'' that can help programer to understand data flows from one core to another.
In fact, it is not enough to indentify false sharing problem according to our understanding. For all problems found in
this paper, it didn't existing a data flow bouncing among different cores. 

\item
DProf needs to manual annotation which helps to find data type and fields of one object for one given memory address.

\item
According to their paper, DProf cannot detect false sharing if multiple objects share the same cache line.
 
\end{itemize}
\end{comment}

\subsection{False Sharing Avoidance}
It is well-known that false sharing problems can affect the performance of application greately~\cite{falseshare:compile,falseshare:schedule}. In order to avoid the effect brought by false sharing, some of previous studies are trying to 
avoid false sharing effect by different approaches. 
Jeremiassen and Eggers~\cite{falseshare:compile} are firtly provided a compiler transformation to adjust the memory layout
of applications though the computation of memory access pattern. 
Chow et al~\cite{falseshare:schedule} are trying to selecting different scheduling parameters for parallel loop, which they
believe to create a more portable code and can eliminate the false sharing for parallel loop. 
Hoard~\cite{BergerMcKinleyBlumofeWilson:ASPLOS2000} provides a new memory allocator to eliminate those false sharing that are caused by heap objects, which is proved to scale well in CMP architecture. 

But none of those can not handle all false sharing problems, for example, false sharing problems caused by runtime parameters or 
actual runtime environment can be missed by tools based on static analysis. 
False sharing problems introduced by global objects can not be avoided by tools like Hoard. 

\subsection{False Sharing Detection}
In order to find the false sharing problems, some tools are designed to find the false sharing problems of applications. 
Currently there are several approaches to find the false sharing problems of multithreaded programs. 

Some are tring to use the hardware simulator to approximate the running on 
actual hardware~\cite{falseshare:simulator} and later they can provide information about cache misses. 
Simulator approach highly depends on the design of simulator which can cause simulation results are far from the reality
and also it is very time-consuming.
Some are tring to use the binary instrumentation technique to get exact access on meory, which can provide exact informations
on memory access~\cite{falseshare:binaryinstrumentation1, falseshare:binaryinstrumentation2}. 
According to their results, the average performance overhead is more than 200X slower 
which can deter the user to deploy their tools.  
Intel's performance tuning utility(PTU)~\cite{detect:ptu, detect:intel}, utilizing event-based sampling to discover instructions
sharing physical cache lines, can give some indication about possible false sharing problems caused by different functions.
PTU can suffer from numerous false positives, different threads with numerous accesses on different words in
the same cache line doesn't always means performance problems if accesses are not issued in an interleaving mode. 
Also, PTU can't differentiate the false sharing problems from true sharing problems when one trivial false sharing happens 
to be same cache line with true sharing (see Fig.~\ref{fig:benchmark3}).

\subsection{Process-based approach}

Grace is a process-based approach to tolerate the concurrency errors, such as deadlock, 
race condition of multithreaded programs. They have a different target with us. 
Grace provides a new model, called as serial model, in order to avoid the concurrency problems. 
The similarity with our work is that they also used process-based approach, thus they can use complete separation 
and page fault handler capture the read/write information from different threads. 
In order to avoid the concurrency problems, Grace forced a serial semantics (same as thread spawning). 
Those threads are spawned first always has the priority to commit results first.
Grace has its own semantics, serial semantics, which is far from the semantics of multithreaded programs. 
Serial semantics also precludes communication between threads, something like conditional variable and barrier. 
Sheriff extends the key insight of Grace, using process to replace threads, but extends to general multithreaded 
programs. 
