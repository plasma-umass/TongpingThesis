
Dynamic analysis tools are widely used to find bugs in applications. They are popular among programmers because of their precision---for many analyses, they report no false positives---and can pinpoint the exact location of errors, down to the individual line of code.

Perhaps the most prominent and widely used dynamic analysis tool for C/C++ applications is Valgrind~\cite{Valgrind}. Valgrind's most popular use case is to check memory errors, including buffer overflows, memory use-after-free errors, and memory leaks.

However, while these dynamic analysis tools are very useful, they are often expensive. Using Valgrind normally slows down applications around $10\times - 100\times$. The most recent work, Google's AddressSanitizer, still imposes about 30\% performance overhead on the detection of buffer overflows and memory use-after-free errors ~\cite{AddressSanitizer}. The significant performance overhead limits the usage of these tools only in the debugging phase. However, it is impossible to discover all bugs in the debugging phase, because a lot of bugs happens either with some specific inputs or at a specific running environment. For example, most discovered buffer overflow errors only occurs when they are feed with a specific input. Thus, it is necessary and helpful to have a detection tool with extremely low overhead so that it can be used in real deployment environment.  

This paper presents a novel dynamic analysis tool with extremely lightweight overhead, which can detect an important class of memory errors that sharing the monotonicity property: when an error occurs, the evidence of its occurrence either remains or grows in the memory so that it can be discovered at a later time. When an evidence is not naturally in the program, it is often possible to plant evidence in order to help a later discovery. For example, existing tools place a canary (a random value) around allocated heap objects, thus they can detect buffer overflows by checking the corruptions of those canaries. 

% What is insight
We present a evidence-triggered dynamic analysis, \doubletake{}, with the following insight: by combining checkpointing with evidence planting, it is possible to let applications run at full speed in the common case (no errors). If we discover the evidence of an error, we can roll back and re-execute the program with instrumentation in order to precisely locate the error. 


\doubletake{} lets applications run at full speed until irrevocable system calls. Then \doubletake{} examines the memory for the evidence of possible memory errors. If it can not find any evidence of errors (common case), \doubletake{} performs checkpointing after irrevocable system calls, by saving the contents of the stack, globals, the heap and registers.  If there is an error detected, \doubletake{} rolls back the program to the most recent checkpoint and re-execute the program. During re-execution of the program, \doubletake{} are collecting necessary information helps diagnose the error. Because re-execution only happens when the program has errors (not the common case), we can employ some heavier techniques in the program re-execution. For example, in order to locate where false sharing occurs, \doubletake{} employs the watchpoint mechanism to keep track of all memory accesses at the corrupted address. Because the overhead of checkpointing and memory checking is amortized over a long execution, \doubletake{} achieves much less overhead than existing tools, where most of them has to intercept every memory access in order to report a memory error timely.

\doubletake{} is a drop-in library that can be linked to the application directly, or be preloaded before execution by setting the LD\_PRELOAD environment variable. 
Because of that, there is no need to re-compile the code, as convenient as using Valgrind.     

We have built three different applications using \doubletake{}: buffer overflow detection, use-after-free detection and memory leak detection. All of these applications run without any false positive, precisely pinpoint the error location, and operate with extremely low overhead. For example, \doubletake{} only runs with just 3\% performance overhead for buffer overflow detection and memory leak detection together, which makes it the fastest detection tool up to date. 

\section{Overview}
\input{doubletake/overview}

\section{Applications}
\input{doubletake/application}

\section{Implementation} 
\input{doubletake/implementation}

\section{Evaluation}
\input{doubletake/evaluation}
